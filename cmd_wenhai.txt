################################ finish ####################################
python -m torch.distributed.launch --nproc_per_node 8 --master_port 29505 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/wenhai/resnext50_32x4d_imagenet/label_dyexp05 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 1.0 label.momentum_label_final 0.6 label.momentum_history 1.0 label.momentum_history_final 0.6

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29506 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/wenhai/resnext50_32x4d_imagenet/label_dyexp06 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 1.0 label.momentum_label_final 0.8 label.momentum_history 1.0 label.momentum_history_final 0.8

################################# to run ###################################
python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 200     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_wh_00 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing True dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear    

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 200     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_wh_01 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear augmentation.use_label_dynamic_history True label.momentum_label 0.9 label.momentum_label_final 0.5 label.momentum_history 0.9 label.momentum_history_final 0.5

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 200     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_wh_02 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 200     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_wh_03 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear augmentation.use_label_dynamic_history True label.momentum_label 1.0 label.momentum_label_final 0.5 label.momentum_history 1.0 label.momentum_history_final 0.5
