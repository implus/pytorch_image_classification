############baseline#############
python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline00 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history False dataset.name ImageNet train.no_weight_decay_on_bn True scheduler.warmup.epochs 5 scheduler.warmup.type linear 


python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.1     train.batch_size 32     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline01 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear 


python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.1     train.batch_size 32     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline02 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing True dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear 


python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline04 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing True dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear     0.7797 acc@5 0.9378

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline0401 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dy0401 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear augmentation.use_label_dynamic_history True label.momentum_label 0.9 label.momentum_label_final 0.5 label.momentum_history 0.9 label.momentum_history_final 0.5
0.7807 0.9402

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dy0402 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear augmentation.use_label_dynamic_history True label.momentum_label 1.0 label.momentum_label_final 0.5 label.momentum_history 1.0 label.momentum_history_final 0.5

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dy0403 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear augmentation.use_label_dynamic_history True label.momentum_label 1.0 label.momentum_label_final 0.6 label.momentum_history 1.0 label.momentum_history_final 0.6

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.1     train.batch_size 32     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline05 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing True dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear  acc@1 0.7763 acc@5 0.9350

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.1     train.batch_size 32     scheduler.epochs 100     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_baseline06 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_smoothing False dataset.name ImageNet scheduler.warmup.epochs 5 scheduler.warmup.type linear  0.7711 acc@5 0.9336
#################################
python -m torch.distributed.launch --nproc_per_node 8 --master_port 29501 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp01 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 0.9 label.momentum_label_final 0.1 label.momentum_history 0.9 label.momentum_history_final 0.1


python -m torch.distributed.launch --nproc_per_node 8 --master_port 29502 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp02 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 0.999 label.momentum_label_final 0.001 label.momentum_history 0.999 label.momentum_history_final 0.001

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29503 train.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp03 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history False dataset.name ImageNet


python -m torch.distributed.launch --nproc_per_node 8 --master_port 29501 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp04 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 0.9 label.momentum_label_final 0.5 label.momentum_history 0.9 label.momentum_history_final 0.5


python -m torch.distributed.launch --nproc_per_node 8 --master_port 29501 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp05 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 0.9 label.momentum_label_final 0.6 label.momentum_history 0.9 label.momentum_history_final 0.6

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29501 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp06 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 0.9 label.momentum_label_final 0.4 label.momentum_history 0.9 label.momentum_history_final 0.4

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29501 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp07 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 1. label.momentum_label_final 0.5 label.momentum_history 1. label.momentum_history_final 0.5

python -m torch.distributed.launch --nproc_per_node 8 --master_port 29501 train_label.py --config configs/imagenet/resnext50_32x4d.yaml train.distributed True     train.base_lr 0.2     train.batch_size 64     scheduler.epochs 120     scheduler.type cosine train.precision O1 train.output_dir experiments/resnext50_32x4d_imagenet/label_dyexp08 augmentation.use_cutout False augmentation.use_random_crop True augmentation.use_label_dynamic_history True dataset.name ImageNet label.momentum_label 0.8 label.momentum_label_final 0.5 label.momentum_history 0.8 label.momentum_history_final 0.5
